{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8583b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d9b6f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vmag</th>\n",
       "      <th>Plx</th>\n",
       "      <th>e_Plx</th>\n",
       "      <th>B-V</th>\n",
       "      <th>Amag</th>\n",
       "      <th>TargetClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.10</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.482</td>\n",
       "      <td>16.845016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.27</td>\n",
       "      <td>21.90</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.999</td>\n",
       "      <td>20.972221</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.61</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>13.853532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.06</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.370</td>\n",
       "      <td>17.506509</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.55</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.902</td>\n",
       "      <td>15.839409</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.31</td>\n",
       "      <td>18.80</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1.336</td>\n",
       "      <td>23.680789</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.64</td>\n",
       "      <td>17.74</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.740</td>\n",
       "      <td>20.884768</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Vmag    Plx  e_Plx    B-V       Amag  TargetClass\n",
       "0   9.10   3.54   1.39  0.482  16.845016            3\n",
       "1   9.27  21.90   3.10  0.999  20.972221            5\n",
       "2   6.61   2.81   0.63 -0.019  13.853532            1\n",
       "3   8.06   7.75   0.97  0.370  17.506509            3\n",
       "4   8.55   2.87   1.11  0.902  15.839409            4\n",
       "5  12.31  18.80   4.99  1.336  23.680789            6\n",
       "6   9.64  17.74   1.30  0.740  20.884768            4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stardf = pd.read_csv(\"..//TG_stars.csv\")\n",
    "stardf.head (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4aafedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vmag</th>\n",
       "      <th>Plx</th>\n",
       "      <th>e_Plx</th>\n",
       "      <th>B-V</th>\n",
       "      <th>Amag</th>\n",
       "      <th>TargetClass</th>\n",
       "      <th>Amag_SQ</th>\n",
       "      <th>Vmag_SQ</th>\n",
       "      <th>B-V_SQ</th>\n",
       "      <th>Plx_SQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.10</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.482</td>\n",
       "      <td>16.845016</td>\n",
       "      <td>3</td>\n",
       "      <td>283.754574</td>\n",
       "      <td>82.8100</td>\n",
       "      <td>0.232324</td>\n",
       "      <td>12.5316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.27</td>\n",
       "      <td>21.90</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.999</td>\n",
       "      <td>20.972221</td>\n",
       "      <td>5</td>\n",
       "      <td>439.834036</td>\n",
       "      <td>85.9329</td>\n",
       "      <td>0.998001</td>\n",
       "      <td>479.6100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.61</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>13.853532</td>\n",
       "      <td>1</td>\n",
       "      <td>191.920338</td>\n",
       "      <td>43.6921</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>7.8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.06</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.370</td>\n",
       "      <td>17.506509</td>\n",
       "      <td>3</td>\n",
       "      <td>306.477840</td>\n",
       "      <td>64.9636</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>60.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.55</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.902</td>\n",
       "      <td>15.839409</td>\n",
       "      <td>4</td>\n",
       "      <td>250.886893</td>\n",
       "      <td>73.1025</td>\n",
       "      <td>0.813604</td>\n",
       "      <td>8.2369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Vmag    Plx  e_Plx    B-V       Amag  TargetClass     Amag_SQ  Vmag_SQ  \\\n",
       "0  9.10   3.54   1.39  0.482  16.845016            3  283.754574  82.8100   \n",
       "1  9.27  21.90   3.10  0.999  20.972221            5  439.834036  85.9329   \n",
       "2  6.61   2.81   0.63 -0.019  13.853532            1  191.920338  43.6921   \n",
       "3  8.06   7.75   0.97  0.370  17.506509            3  306.477840  64.9636   \n",
       "4  8.55   2.87   1.11  0.902  15.839409            4  250.886893  73.1025   \n",
       "\n",
       "     B-V_SQ    Plx_SQ  \n",
       "0  0.232324   12.5316  \n",
       "1  0.998001  479.6100  \n",
       "2  0.000361    7.8961  \n",
       "3  0.136900   60.0625  \n",
       "4  0.813604    8.2369  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars_df_features = stardf.copy()\n",
    "\n",
    "stars_df_features['Amag_SQ'] = stars_df_features['Amag']**2\n",
    "stars_df_features['Vmag_SQ'] = stars_df_features['Vmag']**2\n",
    "stars_df_features['B-V_SQ'] = stars_df_features['B-V']**2\n",
    "stars_df_features['Plx_SQ'] = stars_df_features['Plx']**2\n",
    "\n",
    "\n",
    "stars_df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a95dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9677 entries, 0 to 9676\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Vmag         9677 non-null   float64\n",
      " 1   Plx          9677 non-null   float64\n",
      " 2   e_Plx        9677 non-null   float64\n",
      " 3   B-V          9677 non-null   float64\n",
      " 4   Amag         9677 non-null   float64\n",
      " 5   TargetClass  9677 non-null   int64  \n",
      " 6   Amag_SQ      9677 non-null   float64\n",
      " 7   Vmag_SQ      9677 non-null   float64\n",
      " 8   B-V_SQ       9677 non-null   float64\n",
      " 9   Plx_SQ       9677 non-null   float64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 756.1 KB\n"
     ]
    }
   ],
   "source": [
    "stars_df_features.info ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f17214a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zero = stars_df_features[stars_df_features.TargetClass == 0]\n",
    "df_one = stars_df_features[stars_df_features.TargetClass == 1]\n",
    "df_two = stars_df_features[stars_df_features.TargetClass == 2]\n",
    "df_three = stars_df_features[stars_df_features.TargetClass == 3]\n",
    "df_four = stars_df_features[stars_df_features.TargetClass == 4]\n",
    "df_five = stars_df_features[stars_df_features.TargetClass == 5]\n",
    "df_six = stars_df_features[stars_df_features.TargetClass == 6]\n",
    "df_seven = stars_df_features[stars_df_features.TargetClass == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3ef0583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 10\n",
      "1: 559\n",
      "2 : 1285\n",
      "3 : 2457\n",
      "4 : 2178\n",
      "5 : 2733\n",
      "6 : 433\n",
      "6: 22\n"
     ]
    }
   ],
   "source": [
    "num_of_zero=df_zero.shape[0]\n",
    "num_of_one = df_one.shape[0]\n",
    "num_of_two = df_two.shape[0]\n",
    "num_of_three = df_three.shape[0]\n",
    "num_of_four = df_four.shape[0]\n",
    "num_of_five = df_five.shape[0]\n",
    "num_of_six = df_six.shape[0]\n",
    "num_of_seven = df_seven.shape[0]\n",
    "print(\"0:\",num_of_zero)\n",
    "print(\"1:\",num_of_one)\n",
    "print(\"2 :\",num_of_two)\n",
    "print(\"3 :\",num_of_three)\n",
    "print(\"4 :\",num_of_four)\n",
    "print(\"5 :\",num_of_five)\n",
    "print(\"6 :\",num_of_six)\n",
    "print(\"6:\", num_of_seven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d62e2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b0aa014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group 3 from rfc_model-copy2 had the greatest f1 score? If I increase all units to targetclass 3 will his hold for all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dc8d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zero_upsampled = resample(df_zero, \n",
    "                                 replace=True,    \n",
    "                                 n_samples=num_of_three,    \n",
    "                                 random_state=1) \n",
    "df_one_upsampled = resample(df_one, \n",
    "                                 replace=True,    \n",
    "                                 n_samples=num_of_three,    \n",
    "                                 random_state=1) \n",
    "df_two_upsampled = resample(df_three, \n",
    "                                 replace=True,    \n",
    "                                 n_samples=num_of_three,     \n",
    "                                 random_state=1) \n",
    "df_four_upsampled = resample(df_four, \n",
    "                                 replace=True,    \n",
    "                                 n_samples=num_of_three,     \n",
    "                                 random_state=1) \n",
    "df_five_upsampled = resample(df_five, \n",
    "                                 replace=True,    \n",
    "                                 n_samples=num_of_three,     \n",
    "                                 random_state=1) \n",
    "df_six_upsampled = resample(df_six, \n",
    "                                 replace=True,    \n",
    "                                 n_samples=num_of_three,     \n",
    "                                 random_state=1) \n",
    "df_seven_upsampled = resample(df_seven, \n",
    "                                 replace=True,    \n",
    "                                 n_samples=num_of_three,     \n",
    "                                 random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "970e5f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stardf_resampled1 = pd.concat([df_zero_upsampled, df_one_upsampled])\n",
    "stardf_resampled2 = pd.concat([stardf_resampled1, df_two_upsampled])\n",
    "stardf_resampled3 = pd.concat([stardf_resampled2, df_four_upsampled])\n",
    "stardf_resampled4 = pd.concat([stardf_resampled3, df_five_upsampled])\n",
    "stardf_resampled5 = pd.concat([stardf_resampled4, df_six_upsampled])\n",
    "stardf_resampled = pd.concat([stardf_resampled5, df_seven_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d12682d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vmag</th>\n",
       "      <th>Plx</th>\n",
       "      <th>e_Plx</th>\n",
       "      <th>B-V</th>\n",
       "      <th>Amag</th>\n",
       "      <th>TargetClass</th>\n",
       "      <th>Amag_SQ</th>\n",
       "      <th>Vmag_SQ</th>\n",
       "      <th>B-V_SQ</th>\n",
       "      <th>Plx_SQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6623</th>\n",
       "      <td>8.72</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.390</td>\n",
       "      <td>13.235450</td>\n",
       "      <td>0</td>\n",
       "      <td>175.177135</td>\n",
       "      <td>76.0384</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8907</th>\n",
       "      <td>10.01</td>\n",
       "      <td>4.08</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>18.063301</td>\n",
       "      <td>0</td>\n",
       "      <td>326.282836</td>\n",
       "      <td>100.2001</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>16.6464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9205</th>\n",
       "      <td>8.94</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>1.13</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>11.465750</td>\n",
       "      <td>0</td>\n",
       "      <td>131.463421</td>\n",
       "      <td>79.9236</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6623</th>\n",
       "      <td>8.72</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.390</td>\n",
       "      <td>13.235450</td>\n",
       "      <td>0</td>\n",
       "      <td>175.177135</td>\n",
       "      <td>76.0384</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>9.05</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.976</td>\n",
       "      <td>14.569019</td>\n",
       "      <td>0</td>\n",
       "      <td>212.256303</td>\n",
       "      <td>81.9025</td>\n",
       "      <td>0.952576</td>\n",
       "      <td>1.6129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4142</th>\n",
       "      <td>9.60</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.700</td>\n",
       "      <td>10.752245</td>\n",
       "      <td>7</td>\n",
       "      <td>115.610764</td>\n",
       "      <td>92.1600</td>\n",
       "      <td>7.290000</td>\n",
       "      <td>0.0289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>7.04</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.835</td>\n",
       "      <td>12.559019</td>\n",
       "      <td>7</td>\n",
       "      <td>157.728948</td>\n",
       "      <td>49.5616</td>\n",
       "      <td>8.037225</td>\n",
       "      <td>1.6129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>11.16</td>\n",
       "      <td>5.46</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.264</td>\n",
       "      <td>19.845963</td>\n",
       "      <td>7</td>\n",
       "      <td>393.862256</td>\n",
       "      <td>124.5456</td>\n",
       "      <td>0.069696</td>\n",
       "      <td>29.8116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>10.11</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.401</td>\n",
       "      <td>15.297132</td>\n",
       "      <td>7</td>\n",
       "      <td>234.002262</td>\n",
       "      <td>102.2121</td>\n",
       "      <td>0.160801</td>\n",
       "      <td>1.1881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>9.52</td>\n",
       "      <td>10.27</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.735</td>\n",
       "      <td>19.577852</td>\n",
       "      <td>7</td>\n",
       "      <td>383.292297</td>\n",
       "      <td>90.6304</td>\n",
       "      <td>0.540225</td>\n",
       "      <td>105.4729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17199 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Vmag    Plx  e_Plx    B-V       Amag  TargetClass     Amag_SQ  \\\n",
       "6623   8.72   0.80   1.58  0.390  13.235450            0  175.177135   \n",
       "8907  10.01   4.08   1.40 -0.280  18.063301            0  326.282836   \n",
       "9205   8.94  -0.32   1.13 -0.054  11.465750            0  131.463421   \n",
       "6623   8.72   0.80   1.58  0.390  13.235450            0  175.177135   \n",
       "165    9.05   1.27   1.11  0.976  14.569019            0  212.256303   \n",
       "...     ...    ...    ...    ...        ...          ...         ...   \n",
       "4142   9.60  -0.17   1.61  2.700  10.752245            7  115.610764   \n",
       "93     7.04   1.27   0.70  2.835  12.559019            7  157.728948   \n",
       "4930  11.16   5.46   6.54  0.264  19.845963            7  393.862256   \n",
       "3307  10.11  -1.09   1.52  0.401  15.297132            7  234.002262   \n",
       "2049   9.52  10.27   1.08  0.735  19.577852            7  383.292297   \n",
       "\n",
       "       Vmag_SQ    B-V_SQ    Plx_SQ  \n",
       "6623   76.0384  0.152100    0.6400  \n",
       "8907  100.2001  0.078400   16.6464  \n",
       "9205   79.9236  0.002916    0.1024  \n",
       "6623   76.0384  0.152100    0.6400  \n",
       "165    81.9025  0.952576    1.6129  \n",
       "...        ...       ...       ...  \n",
       "4142   92.1600  7.290000    0.0289  \n",
       "93     49.5616  8.037225    1.6129  \n",
       "4930  124.5456  0.069696   29.8116  \n",
       "3307  102.2121  0.160801    1.1881  \n",
       "2049   90.6304  0.540225  105.4729  \n",
       "\n",
       "[17199 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stardf_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c219a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stardf_resampled.drop('TargetClass', axis=1, inplace=False)\n",
    "Y = stardf_resampled['TargetClass']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state=21, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75030521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    492\n",
       "5    492\n",
       "0    492\n",
       "3    491\n",
       "6    491\n",
       "4    491\n",
       "7    491\n",
       "Name: TargetClass, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16a6380a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3440"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.count ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "031a15f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acc42c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    1966\n",
       "6    1966\n",
       "4    1966\n",
       "3    1966\n",
       "0    1965\n",
       "1    1965\n",
       "5    1965\n",
       "Name: TargetClass, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8109b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95a9907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2107b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by increasing my test size I am able to get a better result, will this be the same if i use up/ downsampling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a19d6c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7432    7\n",
       "7124    6\n",
       "4327    4\n",
       "5723    3\n",
       "1279    6\n",
       "       ..\n",
       "832     6\n",
       "9395    1\n",
       "8426    0\n",
       "8242    3\n",
       "1364    0\n",
       "Name: TargetClass, Length: 13759, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79ec002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#y_0 = np.ones(8)     \n",
    "#y_1 = np.ones(477) + 1 \n",
    "#y_2 = np.ones(1028) + 2 \n",
    "#y_3 = np.ones(1966) + 3 \n",
    "#y_4 = np.ones(1742) + 4 \n",
    "#y_5 = np.ones(2186) + 5 \n",
    "#y_6 = np.ones(346) + 6 \n",
    "#y_7 = np.ones(18) + 7\n",
    "#train_labels= np.concatenate([y_0,y_1, y_2,y_3,y_4,y_5,y_6,y_7])\n",
    "#len(y)\n",
    "\n",
    "#classes=[0,1,2,3,4,5,6,7]\n",
    "#len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0feec7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weights = compute_class_weight(class_weight = \"balanced\", classes= np.unique(train_labels), y= train_labels)\n",
    "#class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7326800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wg={0:121.421875,1:2.03642558,2:0.94491732,3:0.49408698,4:0.55762055,5:0.44436185,6:2.8074422,7:53.96527778}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a3a07b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Training Data : 0.9325532378806599\n",
      "RFC Testing Data: 0.9116279069767442\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf =RandomForestClassifier(n_estimators=200, max_features=\"log2\", max_depth=10).fit(X_train_scaled, Y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test_scaled)\n",
    "\n",
    "print(f'RFC Training Data : {clf.score(X_train_scaled,Y_train)}')\n",
    "print(f'RFC Testing Data: {clf.score(X_test_scaled,Y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e93c9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFC Training Data : 0.8759850148559618\n",
    "#RFC Testing Data: 0.7758264462809917\n",
    "\n",
    "#Achieved with a sample size of 0.2 \n",
    "#n_estimators=200, max_features=\"log2\", max_depth=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a243e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, max_features=&#x27;log2&#x27;, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, max_features=&#x27;log2&#x27;, n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, max_features='log2', n_estimators=200)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = clf\n",
    "classifier\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b72a27a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 30 predictions:   [1 3 3 1 6 4 5 4 6 4 6 6 7 5 0 7 6 4 6 1 4 0 0 5 4 3 0 6 7 7]\n",
      "First 30 actual labels: [1, 3, 3, 1, 6, 4, 5, 4, 6, 4, 6, 6, 7, 5, 0, 7, 6, 4, 6, 1, 4, 0, 0, 5, 4, 3, 0, 6, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "print(f\"First 30 predictions:   {predictions[:30]}\")\n",
    "print(f\"First 30 actual labels: {Y_test[:30].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec4f3b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[492,   0,   0,   0,   0,   0,   0],\n",
       "       [  2, 478,   4,   6,   2,   0,   0],\n",
       "       [  0,  13, 450,  28,   0,   0,   0],\n",
       "       [  0,   3,  44, 391,  51,   2,   0],\n",
       "       [  0,   0,   0,  53, 379,  60,   0],\n",
       "       [  0,   0,   0,   0,  28, 463,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 491]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = Y_test\n",
    "y_pred = classifier.predict(X_test)\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1c5abf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       492\n",
      "           1       0.97      0.97      0.97       492\n",
      "           3       0.90      0.92      0.91       491\n",
      "           4       0.82      0.80      0.81       491\n",
      "           5       0.82      0.77      0.80       492\n",
      "           6       0.88      0.94      0.91       491\n",
      "           7       1.00      1.00      1.00       491\n",
      "\n",
      "    accuracy                           0.91      3440\n",
      "   macro avg       0.91      0.91      0.91      3440\n",
      "weighted avg       0.91      0.91      0.91      3440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2268d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f769a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = sorted(zip(X.columns, clf.feature_importances_), key = lambda x: x[1])\n",
    "cols = [f[0] for f in features]\n",
    "width = [f[1] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(10,10)\n",
    "plt.margins(y=0.001)\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c593c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsampling created a larger feature importance on plx, unlike the previous model which puts more focus on AMAG. \n",
    "#this is potentially an issue, plx doesn't really help loads with star classification. AMAG should be second after B-V. \n",
    "#The good news is that your model will learn considerably more about your minority class and won’t just predict the majority\n",
    "#class for a given observation. The bad news is that it’s also possibly going to overfit to the characteristics of those \n",
    "#observations you’ve just duplicated multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0312513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFC Training Data : 0.8699134478749515\n",
    "#RFC Testing Data: 0.7742768595041323 #n_estimators=200, max_features=\"log2\", max_depth=10\n",
    "#RFC Training Data : 0.9711923524092495\n",
    "#RFC Testing Data: 0.7608471074380165(n_estimators=200, max_features=\"log2\", max_depth=15)\n",
    "\n",
    "\n",
    "#increase sample size= 0.3\n",
    "#RFC Training Data : 0.880702790491658\n",
    "#RFC Testing Data: 0.7796143250688705 #n_estimators=200, max_features=\"log2\", max_depth=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e2c50792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_selection import SelectFromModel\n",
    "#sel = SelectFromModel(clf)\n",
    "#sel.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1546fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_selected_train, X_selected_test, Y_train, Y_test = train_test_split(sel.transform(X), Y)\n",
    "#scaler = StandardScaler().fit(X_selected_train)\n",
    "#X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "#X_selected_test_scaled = scaler.transform(X_selected_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b4b9137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = LogisticRegression()\n",
    "#clf.fit(X_selected_train_scaled, Y_train)\n",
    "#print(f'Training Score: {clf.score(X_selected_train_scaled, Y_train)}')\n",
    "#print(f'Testing Score: {clf.score(X_selected_test_scaled, Y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bb034007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not improve score stick with RFC\n",
    "#test model3- yes this is good- it's not regression so I know it's using distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "99838238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#non linear models need more data to pull from this is why increasing the test size works so well, but how to I go about\n",
    "#upsamping without creating bias? Nothing changes when I use the larger data set so that isn't the issue, it's the distribution. \n",
    "#my only concern now is that I've created bias, I need to figure out how to sort class weights because I'm introducing too much \n",
    "#extra data into my model. It's no longer realistic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5e8e502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets import make_classification\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "# Build a classification task using 3 informative features\n",
    "#X, Y = make_classification(n_samples=1936,\n",
    "                         #  n_features=10,\n",
    "                         #  n_informative=3,\n",
    "                         #  n_redundant=0,\n",
    "                         #  n_repeated=0,\n",
    "                         #  n_classes=2,\n",
    "                          # random_state=0,\n",
    "                          # shuffle=False)\n",
    "\n",
    "\n",
    "#rfc = RandomForestClassifier() \n",
    "\n",
    "#param_grid = { \n",
    "   # 'n_estimators': [100, 200, 500],\n",
    "   # 'max_features': ['auto', 'sqrt', 'log2'],\n",
    "   # 'max_depth': [1,3,5,7,10],    \n",
    "#}\n",
    "\n",
    "#CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "#CV_rfc.fit(X, Y)\n",
    "#print (CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e247abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bb54b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#RFC Training Data : 0.8699134478749515\n",
    "#RFC Testing Data: 0.7742768595041323 #n_estimators=200, max_features=\"log2\", max_depth=10\n",
    "#RFC Training Data : 0.9711923524092495\n",
    "#RFC Testing Data: 0.7608471074380165(n_estimators=200, max_features=\"log2\", max_depth=15)\n",
    "#RFC Training Data : 0.8697842655987599\n",
    "#RFC Testing Data: 0.7706611570247934 (n_estimators=200, max_features=\"auto\", max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a003911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
