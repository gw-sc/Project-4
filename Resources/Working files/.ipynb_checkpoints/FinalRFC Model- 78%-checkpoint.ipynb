{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8583b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d9b6f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vmag</th>\n",
       "      <th>Plx</th>\n",
       "      <th>e_Plx</th>\n",
       "      <th>B-V</th>\n",
       "      <th>Amag</th>\n",
       "      <th>TargetClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.10</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.482</td>\n",
       "      <td>16.845016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.27</td>\n",
       "      <td>21.90</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.999</td>\n",
       "      <td>20.972221</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.61</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>13.853532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.06</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.370</td>\n",
       "      <td>17.506509</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.55</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.902</td>\n",
       "      <td>15.839409</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.31</td>\n",
       "      <td>18.80</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1.336</td>\n",
       "      <td>23.680789</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.64</td>\n",
       "      <td>17.74</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.740</td>\n",
       "      <td>20.884768</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Vmag    Plx  e_Plx    B-V       Amag  TargetClass\n",
       "0   9.10   3.54   1.39  0.482  16.845016            3\n",
       "1   9.27  21.90   3.10  0.999  20.972221            5\n",
       "2   6.61   2.81   0.63 -0.019  13.853532            1\n",
       "3   8.06   7.75   0.97  0.370  17.506509            3\n",
       "4   8.55   2.87   1.11  0.902  15.839409            4\n",
       "5  12.31  18.80   4.99  1.336  23.680789            6\n",
       "6   9.64  17.74   1.30  0.740  20.884768            4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stardf = pd.read_csv(\"..//TG_stars.csv\")\n",
    "stardf.head (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4aafedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vmag</th>\n",
       "      <th>Plx</th>\n",
       "      <th>e_Plx</th>\n",
       "      <th>B-V</th>\n",
       "      <th>Amag</th>\n",
       "      <th>TargetClass</th>\n",
       "      <th>Amag_SQ</th>\n",
       "      <th>Vmag_SQ</th>\n",
       "      <th>B-V_SQ</th>\n",
       "      <th>Plx_SQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.10</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.482</td>\n",
       "      <td>16.845016</td>\n",
       "      <td>3</td>\n",
       "      <td>283.754574</td>\n",
       "      <td>82.8100</td>\n",
       "      <td>0.232324</td>\n",
       "      <td>12.5316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.27</td>\n",
       "      <td>21.90</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.999</td>\n",
       "      <td>20.972221</td>\n",
       "      <td>5</td>\n",
       "      <td>439.834036</td>\n",
       "      <td>85.9329</td>\n",
       "      <td>0.998001</td>\n",
       "      <td>479.6100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.61</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>13.853532</td>\n",
       "      <td>1</td>\n",
       "      <td>191.920338</td>\n",
       "      <td>43.6921</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>7.8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.06</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.370</td>\n",
       "      <td>17.506509</td>\n",
       "      <td>3</td>\n",
       "      <td>306.477840</td>\n",
       "      <td>64.9636</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>60.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.55</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.902</td>\n",
       "      <td>15.839409</td>\n",
       "      <td>4</td>\n",
       "      <td>250.886893</td>\n",
       "      <td>73.1025</td>\n",
       "      <td>0.813604</td>\n",
       "      <td>8.2369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Vmag    Plx  e_Plx    B-V       Amag  TargetClass     Amag_SQ  Vmag_SQ  \\\n",
       "0  9.10   3.54   1.39  0.482  16.845016            3  283.754574  82.8100   \n",
       "1  9.27  21.90   3.10  0.999  20.972221            5  439.834036  85.9329   \n",
       "2  6.61   2.81   0.63 -0.019  13.853532            1  191.920338  43.6921   \n",
       "3  8.06   7.75   0.97  0.370  17.506509            3  306.477840  64.9636   \n",
       "4  8.55   2.87   1.11  0.902  15.839409            4  250.886893  73.1025   \n",
       "\n",
       "     B-V_SQ    Plx_SQ  \n",
       "0  0.232324   12.5316  \n",
       "1  0.998001  479.6100  \n",
       "2  0.000361    7.8961  \n",
       "3  0.136900   60.0625  \n",
       "4  0.813604    8.2369  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars_df_features = stardf.copy()\n",
    "\n",
    "stars_df_features['Amag_SQ'] = stars_df_features['Amag']**2\n",
    "stars_df_features['Vmag_SQ'] = stars_df_features['Vmag']**2\n",
    "stars_df_features['B-V_SQ'] = stars_df_features['B-V']**2\n",
    "stars_df_features['Plx_SQ'] = stars_df_features['Plx']**2\n",
    "#stars_df_features['Sum_AV'] = stars_df_features['Amag'] + stars_df_features['Vmag']\n",
    "#stars_df_features['Sub_AV'] = stars_df_features['Amag'] + stars_df_features['Vmag']\n",
    "\n",
    "stars_df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28a95dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9677 entries, 0 to 9676\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Vmag         9677 non-null   float64\n",
      " 1   Plx          9677 non-null   float64\n",
      " 2   e_Plx        9677 non-null   float64\n",
      " 3   B-V          9677 non-null   float64\n",
      " 4   Amag         9677 non-null   float64\n",
      " 5   TargetClass  9677 non-null   int64  \n",
      " 6   Amag_SQ      9677 non-null   float64\n",
      " 7   Vmag_SQ      9677 non-null   float64\n",
      " 8   B-V_SQ       9677 non-null   float64\n",
      " 9   Plx_SQ       9677 non-null   float64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 756.1 KB\n"
     ]
    }
   ],
   "source": [
    "stars_df_features.info ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c219a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stars_df_features.drop('TargetClass', axis=1, inplace=False)\n",
    "Y = stars_df_features['TargetClass']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state=21, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8b7abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_neigh = 12\n",
    "#K_best = 0\n",
    "#Score_best = 0\n",
    "\n",
    "#for i in range(1,n_neigh):\n",
    "   # KNN = KNeighborsClassifier(n_neighbors=i)\n",
    "    #KNN.fit(X_train,Y_train)\n",
    "    #Y_pred = KNN.predict(X_test)\n",
    "    #if KNN.score(X_test,Y_test) > Score_best:\n",
    "      #  Score_best = KNN.score(X_test,Y_test)\n",
    "       # K_best = i\n",
    "#print(\"neighbors is {} with a test accuracy of {}%\"\"\".format(K_best, (Score_best*100)))\n",
    "#neighbors is 10 with a test accuracy of 52.01446280991735%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75030521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    547\n",
       "3    491\n",
       "4    436\n",
       "2    257\n",
       "1    112\n",
       "6     87\n",
       "7      4\n",
       "0      2\n",
       "Name: TargetClass, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16a6380a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1936"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.count ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "031a15f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acc42c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2186\n",
       "3    1966\n",
       "4    1742\n",
       "2    1028\n",
       "1     447\n",
       "6     346\n",
       "7      18\n",
       "0       8\n",
       "Name: TargetClass, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8109b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0ceba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = KNeighborsClassifier(n_neighbors=5)\n",
    "#model.fit(X_train,Y_train)\n",
    "#Y_pred = KNN.predict(X_test)\n",
    "#print(\"Precision Score : \",precision_score(Y_test, Y_pred, \n",
    "                                          # pos_label='positive',\n",
    "                                           #average='micro'))\n",
    "#print(\"Recall Score : \",recall_score(Y_test, Y_pred, \n",
    "                                           #pos_label='positive',\n",
    "                                           #average='micro'))\n",
    "        \n",
    "#Precision Score :  0.5175619834710744\n",
    "#Recall Score :  0.5175619834710744     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "189f13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier = LogisticRegression()\n",
    "#classifier.fit(X_train, Y_train)\n",
    "\n",
    "#print(f\"LR Training Data: {classifier.score(X_train, Y_train)}\")\n",
    "#print(f\"LR Testing Data: {classifier.score(X_test, Y_test)}\")\n",
    "#LR Training Data: 0.5083322568143651\n",
    "#LR Testing Data: 0.5051652892561983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95a9907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2107b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by increasing my test size I am able to get a better result, will this be the same if i use up/ downsampling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a19d6c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321     4\n",
       "3504    5\n",
       "1325    1\n",
       "2739    4\n",
       "722     5\n",
       "       ..\n",
       "3388    1\n",
       "6378    5\n",
       "15      3\n",
       "7896    4\n",
       "8572    2\n",
       "Name: TargetClass, Length: 7741, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79ec002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#y_0 = np.ones(8)     \n",
    "#y_1 = np.ones(477) + 1 \n",
    "#y_2 = np.ones(1028) + 2 \n",
    "#y_3 = np.ones(1966) + 3 \n",
    "#y_4 = np.ones(1742) + 4 \n",
    "#y_5 = np.ones(2186) + 5 \n",
    "#y_6 = np.ones(346) + 6 \n",
    "#y_7 = np.ones(18) + 7\n",
    "#train_labels= np.concatenate([y_0,y_1, y_2,y_3,y_4,y_5,y_6,y_7])\n",
    "#len(y)\n",
    "\n",
    "#classes=[0,1,2,3,4,5,6,7]\n",
    "#len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0feec7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weights = compute_class_weight(class_weight = \"balanced\", classes= np.unique(train_labels), y= train_labels)\n",
    "#class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7326800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wg={0:121.421875,1:2.03642558,2:0.94491732,3:0.49408698,4:0.55762055,5:0.44436185,6:2.8074422,7:53.96527778}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a3a07b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Training Data : 0.8759850148559618\n",
      "RFC Testing Data: 0.7758264462809917\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf =RandomForestClassifier(n_estimators=200, max_features=\"log2\", max_depth=10).fit(X_train_scaled, Y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test_scaled)\n",
    "\n",
    "print(f'RFC Training Data : {clf.score(X_train_scaled,Y_train)}')\n",
    "print(f'RFC Testing Data: {clf.score(X_test_scaled,Y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFC Training Data : 0.8759850148559618\n",
    "#RFC Testing Data: 0.7758264462809917\n",
    "\n",
    "#Achieved with a sample size of 0.2 \n",
    "#n_estimators=200, max_features=\"log2\", max_depth=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a243e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, max_features=&#x27;log2&#x27;, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, max_features=&#x27;log2&#x27;, n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, max_features='log2', n_estimators=200)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = clf\n",
    "classifier\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b72a27a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 predictions:   [3 2 2 2 4 2 5 3 5 2 2 2 1 5 5 5 5 5 3 3]\n",
      "First 10 actual labels: [3, 3, 2, 1, 5, 1, 5, 3, 5, 2, 2, 2, 1, 5, 5, 5, 5, 5, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "print(f\"First 10 predictions:   {predictions[:20]}\")\n",
    "print(f\"First 10 actual labels: {Y_test[:20].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec4f3b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,  55,  40,  11,   5,   0,   1,   0],\n",
       "       [  0,  19, 214,  21,   3,   0,   0,   0],\n",
       "       [  0,   1,  19, 424,  44,   3,   0,   0],\n",
       "       [  0,   0,   1,  53, 289,  91,   2,   0],\n",
       "       [  0,   0,   1,   2,  46, 474,  24,   0],\n",
       "       [  0,   0,   0,   1,   0,  42,  43,   1],\n",
       "       [  0,   0,   0,   0,   0,   3,   1,   0]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = Y_test\n",
    "y_pred = classifier.predict(X_test)\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1c5abf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.71      0.49      0.58       112\n",
      "           2       0.78      0.83      0.80       257\n",
      "           3       0.83      0.86      0.85       491\n",
      "           4       0.75      0.66      0.70       436\n",
      "           5       0.77      0.87      0.82       547\n",
      "           6       0.61      0.49      0.54        87\n",
      "           7       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.77      1936\n",
      "   macro avg       0.56      0.53      0.54      1936\n",
      "weighted avg       0.77      0.77      0.77      1936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956df497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the issue lies with group 0 and 7 because there isn't enough data in them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2268d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f769a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = sorted(zip(X.columns, clf.feature_importances_), key = lambda x: x[1])\n",
    "cols = [f[0] for f in features]\n",
    "width = [f[1] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(10,10)\n",
    "plt.margins(y=0.001)\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0312513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFC Training Data : 0.8699134478749515\n",
    "#RFC Testing Data: 0.7742768595041323 #n_estimators=200, max_features=\"log2\", max_depth=10\n",
    "#RFC Training Data : 0.9711923524092495\n",
    "#RFC Testing Data: 0.7608471074380165(n_estimators=200, max_features=\"log2\", max_depth=15)\n",
    "\n",
    "\n",
    "#increase sample size= 0.3\n",
    "#RFC Training Data : 0.880702790491658\n",
    "#RFC Testing Data: 0.7796143250688705 #n_estimators=200, max_features=\"log2\", max_depth=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c50792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "sel = SelectFromModel(clf)\n",
    "sel.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1546fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected_train, X_selected_test, Y_train, Y_test = train_test_split(sel.transform(X), Y)\n",
    "scaler = StandardScaler().fit(X_selected_train)\n",
    "X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "X_selected_test_scaled = scaler.transform(X_selected_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b9137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_selected_train_scaled, Y_train)\n",
    "print(f'Training Score: {clf.score(X_selected_train_scaled, Y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_selected_test_scaled, Y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb034007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not improve score stick with RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99838238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#non linear models need more data to pull from this is why increasing the test size works so well, but how to I go about\n",
    "#upsamping without creating bias? Nothing changes when I use the larger data set so that isn't the issue, it's the distribution. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d7f8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e70ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd31076e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba64f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf =RandomForestClassifier(n_estimators=100, max_features=12, max_depth=10).fit(X_train_scaled, Y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test_scaled)\n",
    "\n",
    "print(f'RFC Training Data : {clf.score(X_train_scaled,Y_train)}')\n",
    "print(f'RFC Testing Data: {clf.score(X_test_scaled,Y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Build a classification task using 3 informative features\n",
    "X, Y = make_classification(n_samples=1936,\n",
    "                           n_features=10,\n",
    "                           n_informative=3,\n",
    "                           n_redundant=0,\n",
    "                           n_repeated=0,\n",
    "                           n_classes=2,\n",
    "                           random_state=0,\n",
    "                           shuffle=False)\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier() \n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [1,3,5,7,10],    \n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(X, Y)\n",
    "print (CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e247abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb54b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#RFC Training Data : 0.8699134478749515\n",
    "#RFC Testing Data: 0.7742768595041323 #n_estimators=200, max_features=\"log2\", max_depth=10\n",
    "#RFC Training Data : 0.9711923524092495\n",
    "#RFC Testing Data: 0.7608471074380165(n_estimators=200, max_features=\"log2\", max_depth=15)\n",
    "#RFC Training Data : 0.8697842655987599\n",
    "#RFC Testing Data: 0.7706611570247934 (n_estimators=200, max_features=\"auto\", max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a003911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
