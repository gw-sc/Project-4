{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8583b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6d9b6f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vmag</th>\n",
       "      <th>Plx</th>\n",
       "      <th>e_Plx</th>\n",
       "      <th>B-V</th>\n",
       "      <th>Amag</th>\n",
       "      <th>TargetClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.10</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.482</td>\n",
       "      <td>16.845016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.27</td>\n",
       "      <td>21.90</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.999</td>\n",
       "      <td>20.972221</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.61</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>13.853532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.06</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.370</td>\n",
       "      <td>17.506509</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.55</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.902</td>\n",
       "      <td>15.839409</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.31</td>\n",
       "      <td>18.80</td>\n",
       "      <td>4.99</td>\n",
       "      <td>1.336</td>\n",
       "      <td>23.680789</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.64</td>\n",
       "      <td>17.74</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.740</td>\n",
       "      <td>20.884768</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Vmag    Plx  e_Plx    B-V       Amag  TargetClass\n",
       "0   9.10   3.54   1.39  0.482  16.845016            3\n",
       "1   9.27  21.90   3.10  0.999  20.972221            5\n",
       "2   6.61   2.81   0.63 -0.019  13.853532            1\n",
       "3   8.06   7.75   0.97  0.370  17.506509            3\n",
       "4   8.55   2.87   1.11  0.902  15.839409            4\n",
       "5  12.31  18.80   4.99  1.336  23.680789            6\n",
       "6   9.64  17.74   1.30  0.740  20.884768            4"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stardf = pd.read_csv(\"..//TG_stars.csv\")\n",
    "stardf.head (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b4aafedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vmag</th>\n",
       "      <th>Plx</th>\n",
       "      <th>e_Plx</th>\n",
       "      <th>B-V</th>\n",
       "      <th>Amag</th>\n",
       "      <th>TargetClass</th>\n",
       "      <th>Amag_SQ</th>\n",
       "      <th>Vmag_SQ</th>\n",
       "      <th>B-V_SQ</th>\n",
       "      <th>Plx_SQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.10</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.482</td>\n",
       "      <td>16.845016</td>\n",
       "      <td>3</td>\n",
       "      <td>283.754574</td>\n",
       "      <td>82.8100</td>\n",
       "      <td>0.232324</td>\n",
       "      <td>12.5316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.27</td>\n",
       "      <td>21.90</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.999</td>\n",
       "      <td>20.972221</td>\n",
       "      <td>5</td>\n",
       "      <td>439.834036</td>\n",
       "      <td>85.9329</td>\n",
       "      <td>0.998001</td>\n",
       "      <td>479.6100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.61</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>13.853532</td>\n",
       "      <td>1</td>\n",
       "      <td>191.920338</td>\n",
       "      <td>43.6921</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>7.8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.06</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.370</td>\n",
       "      <td>17.506509</td>\n",
       "      <td>3</td>\n",
       "      <td>306.477840</td>\n",
       "      <td>64.9636</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>60.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.55</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.902</td>\n",
       "      <td>15.839409</td>\n",
       "      <td>4</td>\n",
       "      <td>250.886893</td>\n",
       "      <td>73.1025</td>\n",
       "      <td>0.813604</td>\n",
       "      <td>8.2369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Vmag    Plx  e_Plx    B-V       Amag  TargetClass     Amag_SQ  Vmag_SQ  \\\n",
       "0  9.10   3.54   1.39  0.482  16.845016            3  283.754574  82.8100   \n",
       "1  9.27  21.90   3.10  0.999  20.972221            5  439.834036  85.9329   \n",
       "2  6.61   2.81   0.63 -0.019  13.853532            1  191.920338  43.6921   \n",
       "3  8.06   7.75   0.97  0.370  17.506509            3  306.477840  64.9636   \n",
       "4  8.55   2.87   1.11  0.902  15.839409            4  250.886893  73.1025   \n",
       "\n",
       "     B-V_SQ    Plx_SQ  \n",
       "0  0.232324   12.5316  \n",
       "1  0.998001  479.6100  \n",
       "2  0.000361    7.8961  \n",
       "3  0.136900   60.0625  \n",
       "4  0.813604    8.2369  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars_df_features = stardf.copy()\n",
    "\n",
    "stars_df_features['Amag_SQ'] = stars_df_features['Amag']**2\n",
    "stars_df_features['Vmag_SQ'] = stars_df_features['Vmag']**2\n",
    "stars_df_features['B-V_SQ'] = stars_df_features['B-V']**2\n",
    "stars_df_features['Plx_SQ'] = stars_df_features['Plx']**2\n",
    "#stars_df_features['Sum_AV'] = stars_df_features['Amag'] + stars_df_features['Vmag']\n",
    "#stars_df_features['Sub_AV'] = stars_df_features['Amag'] + stars_df_features['Vmag']\n",
    "\n",
    "stars_df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28a95dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9677 entries, 0 to 9676\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Vmag         9677 non-null   float64\n",
      " 1   Plx          9677 non-null   float64\n",
      " 2   e_Plx        9677 non-null   float64\n",
      " 3   B-V          9677 non-null   float64\n",
      " 4   Amag         9677 non-null   float64\n",
      " 5   TargetClass  9677 non-null   int64  \n",
      " 6   Amag_SQ      9677 non-null   float64\n",
      " 7   Vmag_SQ      9677 non-null   float64\n",
      " 8   B-V_SQ       9677 non-null   float64\n",
      " 9   Plx_SQ       9677 non-null   float64\n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 756.1 KB\n"
     ]
    }
   ],
   "source": [
    "stars_df_features.info ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f17214a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zero = stars_df_features[stars_df_features.TargetClass == 0]\n",
    "df_one = stars_df_features[stars_df_features.TargetClass == 1]\n",
    "df_two = stars_df_features[stars_df_features.TargetClass == 2]\n",
    "df_three = stars_df_features[stars_df_features.TargetClass == 3]\n",
    "df_four = stars_df_features[stars_df_features.TargetClass == 4]\n",
    "df_five = stars_df_features[stars_df_features.TargetClass == 5]\n",
    "df_six = stars_df_features[stars_df_features.TargetClass == 6]\n",
    "df_seven = stars_df_features[stars_df_features.TargetClass == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c3ef0583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 10\n",
      "1: 559\n",
      "2 : 1285\n",
      "3 : 2457\n",
      "4 : 2178\n",
      "5 : 2733\n",
      "6 : 433\n",
      "6: 22\n"
     ]
    }
   ],
   "source": [
    "num_of_zero=df_zero.shape[0]\n",
    "num_of_one = df_one.shape[0]\n",
    "num_of_two = df_two.shape[0]\n",
    "num_of_three = df_three.shape[0]\n",
    "num_of_four = df_four.shape[0]\n",
    "num_of_five = df_five.shape[0]\n",
    "num_of_six = df_six.shape[0]\n",
    "num_of_seven = df_seven.shape[0]\n",
    "print(\"0:\",num_of_zero)\n",
    "print(\"1:\",num_of_one)\n",
    "print(\"2 :\",num_of_two)\n",
    "print(\"3 :\",num_of_three)\n",
    "print(\"4 :\",num_of_four)\n",
    "print(\"5 :\",num_of_five)\n",
    "print(\"6 :\",num_of_six)\n",
    "print(\"6:\", num_of_seven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d62e2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0b0aa014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group 3 from rfc_model-copy2 had the greatest f1 score? If I increase all units to targetclass 3 will his hold for all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4dc8d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zero_upsampled = resample(df_zero, \n",
    "                                 replace=True,    \n",
    "                                 n_samples=num_of_three,    \n",
    "                                 random_state=1) \n",
    "df_one_upsampled = resample(df_one, \n",
    "                                 replace=True,    \n",
    "                                 n_samples=num_of_three,    \n",
    "                                 random_state=1) \n",
    "df_two_upsampled = resample(df_three, \n",
    "                                 replace=True,    \n",
    "                                 n_samples=num_of_three,     \n",
    "                                 random_state=1) \n",
    "df_four_upsampled = resample(df_four, \n",
    "                                 replace=True,    \n",
    "                                 n_samples=num_of_three,     \n",
    "                                 random_state=1) \n",
    "df_five_upsampled = resample(df_five, \n",
    "                                 replace=True,    \n",
    "                                 n_samples=num_of_three,     \n",
    "                                 random_state=1) \n",
    "df_six_upsampled = resample(df_six, \n",
    "                                 replace=True,    \n",
    "                                 n_samples=num_of_three,     \n",
    "                                 random_state=1) \n",
    "df_seven_upsampled = resample(df_seven, \n",
    "                                 replace=True,    \n",
    "                                 n_samples=num_of_three,     \n",
    "                                 random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "970e5f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stardf_resampled1 = pd.concat([df_zero_upsampled, df_one_upsampled])\n",
    "stardf_resampled2 = pd.concat([stardf_resampled1, df_two_upsampled])\n",
    "stardf_resampled3 = pd.concat([stardf_resampled2, df_four_upsampled])\n",
    "stardf_resampled4 = pd.concat([stardf_resampled3, df_five_upsampled])\n",
    "stardf_resampled5 = pd.concat([stardf_resampled4, df_six_upsampled])\n",
    "stardf_resampled = pd.concat([stardf_resampled5, df_seven_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4d12682d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vmag</th>\n",
       "      <th>Plx</th>\n",
       "      <th>e_Plx</th>\n",
       "      <th>B-V</th>\n",
       "      <th>Amag</th>\n",
       "      <th>TargetClass</th>\n",
       "      <th>Amag_SQ</th>\n",
       "      <th>Vmag_SQ</th>\n",
       "      <th>B-V_SQ</th>\n",
       "      <th>Plx_SQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6623</th>\n",
       "      <td>8.72</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.390</td>\n",
       "      <td>13.235450</td>\n",
       "      <td>0</td>\n",
       "      <td>175.177135</td>\n",
       "      <td>76.0384</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8907</th>\n",
       "      <td>10.01</td>\n",
       "      <td>4.08</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>18.063301</td>\n",
       "      <td>0</td>\n",
       "      <td>326.282836</td>\n",
       "      <td>100.2001</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>16.6464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9205</th>\n",
       "      <td>8.94</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>1.13</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>11.465750</td>\n",
       "      <td>0</td>\n",
       "      <td>131.463421</td>\n",
       "      <td>79.9236</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6623</th>\n",
       "      <td>8.72</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.390</td>\n",
       "      <td>13.235450</td>\n",
       "      <td>0</td>\n",
       "      <td>175.177135</td>\n",
       "      <td>76.0384</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>9.05</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.976</td>\n",
       "      <td>14.569019</td>\n",
       "      <td>0</td>\n",
       "      <td>212.256303</td>\n",
       "      <td>81.9025</td>\n",
       "      <td>0.952576</td>\n",
       "      <td>1.6129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4142</th>\n",
       "      <td>9.60</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.700</td>\n",
       "      <td>10.752245</td>\n",
       "      <td>7</td>\n",
       "      <td>115.610764</td>\n",
       "      <td>92.1600</td>\n",
       "      <td>7.290000</td>\n",
       "      <td>0.0289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>7.04</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.835</td>\n",
       "      <td>12.559019</td>\n",
       "      <td>7</td>\n",
       "      <td>157.728948</td>\n",
       "      <td>49.5616</td>\n",
       "      <td>8.037225</td>\n",
       "      <td>1.6129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>11.16</td>\n",
       "      <td>5.46</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.264</td>\n",
       "      <td>19.845963</td>\n",
       "      <td>7</td>\n",
       "      <td>393.862256</td>\n",
       "      <td>124.5456</td>\n",
       "      <td>0.069696</td>\n",
       "      <td>29.8116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>10.11</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.401</td>\n",
       "      <td>15.297132</td>\n",
       "      <td>7</td>\n",
       "      <td>234.002262</td>\n",
       "      <td>102.2121</td>\n",
       "      <td>0.160801</td>\n",
       "      <td>1.1881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>9.52</td>\n",
       "      <td>10.27</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.735</td>\n",
       "      <td>19.577852</td>\n",
       "      <td>7</td>\n",
       "      <td>383.292297</td>\n",
       "      <td>90.6304</td>\n",
       "      <td>0.540225</td>\n",
       "      <td>105.4729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17199 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Vmag    Plx  e_Plx    B-V       Amag  TargetClass     Amag_SQ  \\\n",
       "6623   8.72   0.80   1.58  0.390  13.235450            0  175.177135   \n",
       "8907  10.01   4.08   1.40 -0.280  18.063301            0  326.282836   \n",
       "9205   8.94  -0.32   1.13 -0.054  11.465750            0  131.463421   \n",
       "6623   8.72   0.80   1.58  0.390  13.235450            0  175.177135   \n",
       "165    9.05   1.27   1.11  0.976  14.569019            0  212.256303   \n",
       "...     ...    ...    ...    ...        ...          ...         ...   \n",
       "4142   9.60  -0.17   1.61  2.700  10.752245            7  115.610764   \n",
       "93     7.04   1.27   0.70  2.835  12.559019            7  157.728948   \n",
       "4930  11.16   5.46   6.54  0.264  19.845963            7  393.862256   \n",
       "3307  10.11  -1.09   1.52  0.401  15.297132            7  234.002262   \n",
       "2049   9.52  10.27   1.08  0.735  19.577852            7  383.292297   \n",
       "\n",
       "       Vmag_SQ    B-V_SQ    Plx_SQ  \n",
       "6623   76.0384  0.152100    0.6400  \n",
       "8907  100.2001  0.078400   16.6464  \n",
       "9205   79.9236  0.002916    0.1024  \n",
       "6623   76.0384  0.152100    0.6400  \n",
       "165    81.9025  0.952576    1.6129  \n",
       "...        ...       ...       ...  \n",
       "4142   92.1600  7.290000    0.0289  \n",
       "93     49.5616  8.037225    1.6129  \n",
       "4930  124.5456  0.069696   29.8116  \n",
       "3307  102.2121  0.160801    1.1881  \n",
       "2049   90.6304  0.540225  105.4729  \n",
       "\n",
       "[17199 rows x 10 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stardf_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5c219a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stardf_resampled.drop('TargetClass', axis=1, inplace=False)\n",
    "Y = stardf_resampled['TargetClass']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state=21, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c8b7abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_neigh = 12\n",
    "#K_best = 0\n",
    "#Score_best = 0\n",
    "\n",
    "#for i in range(1,n_neigh):\n",
    "   # KNN = KNeighborsClassifier(n_neighbors=i)\n",
    "    #KNN.fit(X_train,Y_train)\n",
    "    #Y_pred = KNN.predict(X_test)\n",
    "    #if KNN.score(X_test,Y_test) > Score_best:\n",
    "      #  Score_best = KNN.score(X_test,Y_test)\n",
    "       # K_best = i\n",
    "#print(\"neighbors is {} with a test accuracy of {}%\"\"\".format(K_best, (Score_best*100)))\n",
    "#neighbors is 10 with a test accuracy of 52.01446280991735%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "75030521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    492\n",
       "5    492\n",
       "0    492\n",
       "3    491\n",
       "6    491\n",
       "4    491\n",
       "7    491\n",
       "Name: TargetClass, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "16a6380a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3440"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.count ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "031a15f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "acc42c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    1966\n",
       "6    1966\n",
       "4    1966\n",
       "3    1966\n",
       "0    1965\n",
       "1    1965\n",
       "5    1965\n",
       "Name: TargetClass, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8109b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f0ceba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = KNeighborsClassifier(n_neighbors=5)\n",
    "#model.fit(X_train,Y_train)\n",
    "#Y_pred = KNN.predict(X_test)\n",
    "#print(\"Precision Score : \",precision_score(Y_test, Y_pred, \n",
    "                                          # pos_label='positive',\n",
    "                                           #average='micro'))\n",
    "#print(\"Recall Score : \",recall_score(Y_test, Y_pred, \n",
    "                                           #pos_label='positive',\n",
    "                                           #average='micro'))\n",
    "        \n",
    "#Precision Score :  0.5175619834710744\n",
    "#Recall Score :  0.5175619834710744     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "189f13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier = LogisticRegression()\n",
    "#classifier.fit(X_train, Y_train)\n",
    "\n",
    "#print(f\"LR Training Data: {classifier.score(X_train, Y_train)}\")\n",
    "#print(f\"LR Testing Data: {classifier.score(X_test, Y_test)}\")\n",
    "#LR Training Data: 0.5083322568143651\n",
    "#LR Testing Data: 0.5051652892561983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "95a9907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2107b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by increasing my test size I am able to get a better result, will this be the same if i use up/ downsampling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a19d6c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7432    7\n",
       "7124    6\n",
       "4327    4\n",
       "5723    3\n",
       "1279    6\n",
       "       ..\n",
       "832     6\n",
       "9395    1\n",
       "8426    0\n",
       "8242    3\n",
       "1364    0\n",
       "Name: TargetClass, Length: 13759, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "79ec002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#y_0 = np.ones(8)     \n",
    "#y_1 = np.ones(477) + 1 \n",
    "#y_2 = np.ones(1028) + 2 \n",
    "#y_3 = np.ones(1966) + 3 \n",
    "#y_4 = np.ones(1742) + 4 \n",
    "#y_5 = np.ones(2186) + 5 \n",
    "#y_6 = np.ones(346) + 6 \n",
    "#y_7 = np.ones(18) + 7\n",
    "#train_labels= np.concatenate([y_0,y_1, y_2,y_3,y_4,y_5,y_6,y_7])\n",
    "#len(y)\n",
    "\n",
    "#classes=[0,1,2,3,4,5,6,7]\n",
    "#len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0feec7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weights = compute_class_weight(class_weight = \"balanced\", classes= np.unique(train_labels), y= train_labels)\n",
    "#class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7326800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wg={0:121.421875,1:2.03642558,2:0.94491732,3:0.49408698,4:0.55762055,5:0.44436185,6:2.8074422,7:53.96527778}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3a3a07b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Training Data : 0.9324805581801003\n",
      "RFC Testing Data: 0.9116279069767442\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf =RandomForestClassifier(n_estimators=200, max_features=\"log2\", max_depth=10).fit(X_train_scaled, Y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test_scaled)\n",
    "\n",
    "print(f'RFC Training Data : {clf.score(X_train_scaled,Y_train)}')\n",
    "print(f'RFC Testing Data: {clf.score(X_test_scaled,Y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "22657a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >:) got ya b*tch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e93c9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFC Training Data : 0.8759850148559618\n",
    "#RFC Testing Data: 0.7758264462809917\n",
    "\n",
    "#Achieved with a sample size of 0.2 \n",
    "#n_estimators=200, max_features=\"log2\", max_depth=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2a243e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, max_features=&#x27;log2&#x27;, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, max_features=&#x27;log2&#x27;, n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, max_features='log2', n_estimators=200)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = clf\n",
    "classifier\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b72a27a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 30 predictions:   [1 3 3 1 6 4 5 4 6 4 6 6 7 5 0 7 6 4 6 1 4 0 0 5 4 3 0 6 7 7]\n",
      "First 30 actual labels: [4, 6, 7, 3, 6, 3, 6, 1, 3, 3, 4, 5, 1, 0, 5, 4, 6, 4, 5, 0, 6, 5, 7, 7, 4, 7, 1, 7, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "print(f\"First 30 predictions:   {predictions[:30]}\")\n",
    "print(f\"First 30 actual labels: {Y_test[:30].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ec4f3b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[492,   0,   0,   0,   0,   0,   0],\n",
       "       [  2, 477,   5,   6,   2,   0,   0],\n",
       "       [  0,  12, 453,  26,   0,   0,   0],\n",
       "       [  0,   3,  45, 389,  52,   2,   0],\n",
       "       [  0,   0,   0,  54, 378,  60,   0],\n",
       "       [  0,   0,   0,   0,  26, 465,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 491]], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = Y_test\n",
    "y_pred = classifier.predict(X_test)\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b1c5abf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       492\n",
      "           1       0.97      0.97      0.97       492\n",
      "           3       0.90      0.92      0.91       491\n",
      "           4       0.82      0.79      0.81       491\n",
      "           5       0.83      0.77      0.80       492\n",
      "           6       0.88      0.95      0.91       491\n",
      "           7       1.00      1.00      1.00       491\n",
      "\n",
      "    accuracy                           0.91      3440\n",
      "   macro avg       0.91      0.91      0.91      3440\n",
      "weighted avg       0.91      0.91      0.91      3440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "956df497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it works? Maybe, I hope so. I think it's good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d2268d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2f769a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = sorted(zip(X.columns, clf.feature_importances_), key = lambda x: x[1])\n",
    "cols = [f[0] for f in features]\n",
    "width = [f[1] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_size_inches(10,10)\n",
    "plt.margins(y=0.001)\n",
    "\n",
    "ax.barh(y=cols, width=width)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c593c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsampling created a larger feature importance on plx, unlike the previous model which puts more focus on AMAG. \n",
    "#this is potentially an issue, plx doesn't really help loads with star classification. AMAG should be second after B-V. \n",
    "#The good news is that your model will learn considerably more about your minority class and won’t just predict the majority\n",
    "#class for a given observation. The bad news is that it’s also possibly going to overfit to the characteristics of those \n",
    "#observations you’ve just duplicated multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0312513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFC Training Data : 0.8699134478749515\n",
    "#RFC Testing Data: 0.7742768595041323 #n_estimators=200, max_features=\"log2\", max_depth=10\n",
    "#RFC Training Data : 0.9711923524092495\n",
    "#RFC Testing Data: 0.7608471074380165(n_estimators=200, max_features=\"log2\", max_depth=15)\n",
    "\n",
    "\n",
    "#increase sample size= 0.3\n",
    "#RFC Training Data : 0.880702790491658\n",
    "#RFC Testing Data: 0.7796143250688705 #n_estimators=200, max_features=\"log2\", max_depth=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e2c50792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_selection import SelectFromModel\n",
    "#sel = SelectFromModel(clf)\n",
    "#sel.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1546fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_selected_train, X_selected_test, Y_train, Y_test = train_test_split(sel.transform(X), Y)\n",
    "#scaler = StandardScaler().fit(X_selected_train)\n",
    "#X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "#X_selected_test_scaled = scaler.transform(X_selected_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b4b9137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = LogisticRegression()\n",
    "#clf.fit(X_selected_train_scaled, Y_train)\n",
    "#print(f'Training Score: {clf.score(X_selected_train_scaled, Y_train)}')\n",
    "#print(f'Testing Score: {clf.score(X_selected_test_scaled, Y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bb034007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not improve score stick with RFC\n",
    "#test model3- yes this is good- it's not regression so I know it's using distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "99838238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#non linear models need more data to pull from this is why increasing the test size works so well, but how to I go about\n",
    "#upsamping without creating bias? Nothing changes when I use the larger data set so that isn't the issue, it's the distribution. \n",
    "#my only concern now is that I've created bias, I need to figure out how to sort class weights because I'm introducing too much \n",
    "#extra data into my model. It's no longer realistic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5e8e502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets import make_classification\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "# Build a classification task using 3 informative features\n",
    "#X, Y = make_classification(n_samples=1936,\n",
    "                         #  n_features=10,\n",
    "                         #  n_informative=3,\n",
    "                         #  n_redundant=0,\n",
    "                         #  n_repeated=0,\n",
    "                         #  n_classes=2,\n",
    "                          # random_state=0,\n",
    "                          # shuffle=False)\n",
    "\n",
    "\n",
    "#rfc = RandomForestClassifier() \n",
    "\n",
    "#param_grid = { \n",
    "   # 'n_estimators': [100, 200, 500],\n",
    "   # 'max_features': ['auto', 'sqrt', 'log2'],\n",
    "   # 'max_depth': [1,3,5,7,10],    \n",
    "#}\n",
    "\n",
    "#CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "#CV_rfc.fit(X, Y)\n",
    "#print (CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e247abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bb54b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#RFC Training Data : 0.8699134478749515\n",
    "#RFC Testing Data: 0.7742768595041323 #n_estimators=200, max_features=\"log2\", max_depth=10\n",
    "#RFC Training Data : 0.9711923524092495\n",
    "#RFC Testing Data: 0.7608471074380165(n_estimators=200, max_features=\"log2\", max_depth=15)\n",
    "#RFC Training Data : 0.8697842655987599\n",
    "#RFC Testing Data: 0.7706611570247934 (n_estimators=200, max_features=\"auto\", max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a003911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
